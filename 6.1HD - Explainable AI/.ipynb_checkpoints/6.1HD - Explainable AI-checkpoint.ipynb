{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub: https://github.com/applecrumble123/SIT799_Human_Aligned_Artificial_Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your assignment this week! \n",
    "\n",
    "To better understand explainable AI, in this assignment, we will look at the __LIME__ framework to explain potential black-box machine learning models in a model-agnostic way. We use a real-world dataset on Census income, also known as the __[*Adult dataset*](https://archive.ics.uci.edu/ml/datasets/Adult)__ available in the *UCI* ML Repository where we will predict if the potential income of people is more than $50K/year or not.\n",
    "\n",
    "For this assignment, we will use: \n",
    "\n",
    "- [XGBoost](https://xgboost.readthedocs.io/en/latest/) (XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable.). Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.\n",
    "- [Decision Tree](https://en.wikipedia.org/wiki/Decision_tree) which is a decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements. Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal, but are also a popular tool in machine learning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__[LIME GitHub](https://github.com/marcotcr/lime)__\n",
    "\n",
    "\n",
    "**After this assignment you will be able to:** use the __LIME__ framework to explain potential black-box machine learning models in a model-agnostic way.\n",
    "\n",
    "\n",
    "Let's get started! Run the following cell to install all the packages you will need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "#!pip install matplotlib\n",
    "#!pip install lime\n",
    "#!pip install shap\n",
    "#!pip install sklearn\n",
    "#!pip install xgboost\n",
    "#!pip install graphviz\n",
    "#!pip install pydot\n",
    "#!pip install pydotplus\n",
    "#!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to load the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1626546b5c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlime_tabular\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLimeTabularExplainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lime'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import shap\n",
    "import itertools\n",
    "\n",
    "##\n",
    "from utils import *\n",
    "##\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import graphviz\n",
    "from io import StringIO\n",
    "from sklearn import datasets,tree\n",
    "import pydot\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the census dataset. Run the following cell to load the features `X` and the labels `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "X_raw, y = shap.datasets.adult(display=True)\n",
    "\n",
    "X_raw = X_raw.drop(columns=['Capital Gain']) # These two features are intentionally removed.\n",
    "X_raw = X_raw.drop(columns=['Capital Loss']) # These two features are intentionally removed.\n",
    "\n",
    "labels = np.array([int(label) for label in y])\n",
    "\n",
    "print('The shape of X_raw is: ',X_raw.shape)\n",
    "print('The shape of y is: ',labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've loaded:\n",
    "\n",
    "- `X_raw`: a DataFrame containing 32,561 instances with 12 features.\n",
    "- `y`: the list of binary labels for the 32,561 examples. If salary of instance $i$ is more than \\\\$50K: $y^{(i)} = 1$ otherwise: $y^{(i)} = 0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Census Income Dataset\n",
    "\n",
    "Let's now take a look at our dataset attributes and understand their meaning and significance.\n",
    "\n",
    "\n",
    "|Num| Attribute Name | Type | Description |\n",
    "|----|----------------------------------------------------------|------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "|1| Age | Continuous | Represents age of the person <br>(Private, Self-emp-not-inc, Self-emp-inc, Federal-gov,  <br>Local-gov, State-gov, Without-pay, Never-worked)|\n",
    "|2| Workclass | Categorical | Represents the workclass of the person. <br> (Private, Self-emp-not-inc, Self-emp-inc, Federal-gov,<br> Local-gov, State-gov, Without-pay, Never-worked). |\n",
    "|3| Education-Num | Categorical | Numeric representation of educational qualification.<br>Ranges from 1-16.<br>(Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, <br>9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool) |\n",
    "|4| Marital Status | Categorical | Represents the marital status of the person<br>(Married-civ-spouse, Divorced, Never-married, Separated, <br>Widowed, Married-spouse-absent, Married-AF-spouse) |\n",
    "|5| Occupation | Categorical | Represents the type of profession job of the person<br>(Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, <br>Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, <br>Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, <br>Armed-Forces) |\n",
    "|6| Relationship | Categorical | Represents the relationship status of the person<br>(Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried) |\n",
    "|7| Race | Categorical | Represents the race of the person<br>(White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black) |\n",
    "|8| Sex | Categorical | Represents the gender of the person<br>(Female, Male) |\n",
    "|9| Capital Gain | Continuous | The total capital gain for the person |\n",
    "|10| Capital Loss | Continuous | The total capital loss for the person |\n",
    "|11| Hours per week | Continuous | Total hours spent working per week |\n",
    "|12| Country | Categorical | The country where the person was born |\n",
    "|13| Income Label  | Categorical | The class label column is the one we want to predict |     \n",
    "\n",
    "\n",
    "\n",
    "We have a total of 12 features and our objective is to predict if the income of a person will be more than $\\$50$K  (True) or less than $\\$50$K (False). Hence we will be building and interpreting a classification model. \n",
    "\n",
    "Let's have a look at the first three instances of the dataset (you can use `X.head(3)` to see the content of the dataset):\n",
    "\n",
    "\n",
    "![](images/dataset.png)\n",
    "\n",
    "\n",
    "For example, the first person is 39 years old, works for the state governement, is a Male and was born in the US. By using `y[0:3]` you can get  binary values indicating whether these persons have an income higher than $\\$50$K or no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "Converting the categorical columns with string values to numeric representations. Typically the XGBoost model can handle categorical data natively being a tree-based model so we don't one-hot encode the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "cat_cols = X_raw.select_dtypes(['category']).columns\n",
    "\n",
    "for col in cat_cols:\n",
    "    mapping[col] = dict( enumerate(X_raw[col].cat.categories ) )\n",
    "indices_cat_cols = [ list(X_raw.columns).index(x) for x in cat_cols ]\n",
    "\n",
    "X = X_raw.copy()\n",
    "X[cat_cols] = X_raw[cat_cols].apply(lambda x: x.cat.codes)\n",
    "headers=list(X.columns)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the distribution of people with <=  $\\$50$K (0) and > $\\$50$K (1) income:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([0], height=[Counter(labels)[0]], color=\"green\")\n",
    "plt.bar([1], height=[Counter(labels)[1]], color=\"red\")\n",
    "plt.xticks([0, 1], ['<=$50K\\n'+str(Counter(labels)[0])+' instances',\n",
    "                    '>$50K\\n'+str(Counter(labels)[1])+' instances'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train and Test Datasets\n",
    "\n",
    "As in any Machine Learning, we need to partition the dataset into two subsets -- a training and testset. Please note that in practice, the dataset needs to be partitioned into three subsets, the third once being the validation set which will be used for hyperparameters tuning. However, in this assignment, we will not tune the hyperparameters.\n",
    "\n",
    "Run the following to split the dataset accordingly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42, stratify=y)\n",
    "print('The shape of training set is: ',X_train.shape)\n",
    "print('The shape of test set is: ',X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've created:\n",
    "\n",
    "- `X_train`: a trainig DataFrame containing 22,792 instances used for training.\n",
    "- `y_train`: the list of binary labels for the 22,792 instances of the training set.\n",
    "- `X_test`: a test DataFrame containing 9,769 instances used for  testing.\n",
    "- `y_test`: the list of binary labels for the 9,769 instances of the test set.\n",
    "\n",
    "We note that since we are using a stratified splitting, the distribution of samples in the training and test set is similar to the distribution in the dataset, i.e., roughly 24% of positive examples in each subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classification model\n",
    "\n",
    "Now we train and build a boosting classification model on our training data using [XGBoost](https://xgboost.readthedocs.io/en/latest/) (XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable.). Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.\n",
    "\n",
    "Run the following to start the training of the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgc = xgb.XGBClassifier(n_estimators=500, max_depth=5, base_score=0.5,\n",
    "                        objective='binary:logistic', random_state=42)\n",
    "xgc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on the test data\n",
    "\n",
    "Now that the classifier is trained, let's make few predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgc.predict(X_test)\n",
    "print(\"The values predicted for the first 20 test examples are:\")\n",
    "print(predictions[:20])\n",
    "\n",
    "print(\"The true values are:\")\n",
    "print(y_test[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our classier is making only 2 errors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance \n",
    " Let's now evaluate the performance of our classifier on the test set. For that, we will call `sklearn.metrics.classification_report()` which returns a text report showing the main classification metrics including: Presicion, Recall, and F1-Score. The reported averages include macro average (averaging the unweighted mean per label) and weighted average (averaging the support-weighted mean per label). \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more details, let's print the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = list(set(labels))\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_labels,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Task 1**: Please provide comments on the performance of the classifier.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The classifier has a relatively high accuracy, precision and recall score for label 0 but a relatively low accuracy, precision and recall score for label 1. The classifer is able to perform well to classify label 0 but perform poorly when classifying label 1. The number of correctly classified instances is significantly higher than the wrongly classfied instance for class label 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance:\n",
    "\n",
    "The global feature importance calcuations that come with XGBoost, enables us to view feature importances based on the following:\n",
    "\n",
    "- **Feature Weights**: This is based on the number of times a feature appears in a tree across the ensemble of trees.\n",
    "- **Gain**: This is based on the average gain of splits which use the feature.\n",
    "- **Coverage**: This is based on the average coverage (number of samples affected) of splits which use the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 15))\n",
    "title = fig.suptitle(\"Default Feature Importances from XGBoost\", fontsize=14)\n",
    "\n",
    "ax1 = fig.add_subplot(3,1, 1)\n",
    "xgb.plot_importance(xgc, importance_type='weight', ax=ax1)\n",
    "t = ax1.set_title(\"Feature Importance - Feature Weight\")\n",
    "\n",
    "ax2 = fig.add_subplot(3,1, 2)\n",
    "xgb.plot_importance(xgc, importance_type='gain', ax=ax2)\n",
    "t = ax2.set_title(\"Feature Importance - Split Mean Gain\")\n",
    "\n",
    "ax3 = fig.add_subplot(3,1, 3)\n",
    "xgb.plot_importance(xgc, importance_type='cover', ax=ax3)\n",
    "t = ax3.set_title(\"Feature Importance - Sample Coverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Task 2**: Please provide comments on the above global feature importance calcuations.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the feature weight, it refers to the percentage representing the relative number of times a particular feature occurs in the trees of the model. With respect to the chart above, it shows that \"Age\" has the highest percentage weight over weights of all features.\n",
    "\n",
    "For the split mean gain, it is the relative contribution of the corresponding feature to the model calculated by taking each feature’s contribution for each tree in the model. The feature with a higher split mean gain when compared to another feature implies it is more important for generating a prediction. With regards to the chart above, it shows that the \"Relationship\" feature is the most important feature for generating a prediction.\n",
    "\n",
    "For the sample coverage, it refers to the relative number of observations related to this feature. With respect to the chart above, it shows that \"Country\" is the feature with the highest observations to decide a leaf node with respect to all the trees in the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretation Methods\n",
    "\n",
    "\n",
    "![](images/Figure5-452aaf48771d7e201175954c1de6eed1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# LIME:\n",
    "\n",
    "Lime is able to explain any black box classifier, with two or more classes. All we require is that the classifier implements a function that takes in raw text or a numpy array and outputs a probability for each class. LIME tries to fit a global surrogate model, LIME focuses on fitting local surrogate models to explain why single predictions were made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since XGBoost has some issues with feature name ordering when building models with dataframes (we also needed feature names in the previous `plot_importance()` calls), we will build our same model with numpy arrays to make LIME work. Remember the model being built is the same ensemble model which we treat as our black box machine learning model.\n",
    "\n",
    "Note the difference with the previous `fit` call:\n",
    "\n",
    "<center> <b>xgc_np.fit(X_train, y_train)</b> vs. <b>xgc_np.fit(X_train.values, y_train)</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgc_np = xgb.XGBClassifier(n_estimators=500, max_depth=5, base_score=0.5,\n",
    "                        objective='binary:logistic', random_state=42)\n",
    "mymodel = xgc_np.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`LimeTabularExplainer`__ class helps in explaining predictions on tabular (i.e. matrix) data. For numerical features, it perturbs them by sampling from a Normal(0,1) and doing the inverse operation of mean-centering and scaling, according to the means and stds in the training data. For categorical features, it perturbs by sampling according to the training distribution, and making a binary feature that is 1 when the value is the same as the instance being explained. \n",
    "\n",
    "\n",
    "__`explain_instance()`__ function generates explanations for a prediction. First, we generate neighborhood data by randomly perturbing features from the instance. We then learn locally weighted linear (surrogate) models on this neighborhood data to explain each of the classes in an interpretable way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=list(X.columns)\n",
    "explainer = LimeTabularExplainer(X_train.values, feature_names=headers, discretize_continuous=True,\n",
    "                                 categorical_features=indices_cat_cols,\n",
    "                                 class_names=['<= $50K', '> $50K'],verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When a person's income <= $50K\n",
    "\n",
    "Lime shows which features were the most influential in the model taking the correct decision of predicting the person's income as below $50K. The below explanation shows features each contributing to push the model output from the base value (the average model output over the training dataset we passed) to the actual model output. Features pushing the prediction higher are shown in red, those pushing the prediction lower are in green."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Task 3**: Please find a person for which the income is <= $\\$50$K and the prediction is correct.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change only the value of to select that person:\n",
    "i = 1\n",
    "###########\n",
    "\n",
    "exp1 = explainer.explain_instance(X_test.iloc[i].values, xgc_np.predict_proba, \n",
    "                                  distance_metric='euclidean', \n",
    "                                  num_features=len(X_test.iloc[i].values))\n",
    "proba1 = xgc_np.predict_proba(X_test.values)[i]\n",
    "\n",
    "print(\"********************\")\n",
    "print('Test id: ' , i)\n",
    "print('Probability(',exp1.class_names[0],\") =\", exp1.predict_proba[0])\n",
    "print('Probability(',exp1.class_names[1],\") =\", exp1.predict_proba[1])\n",
    "print('Predicted Label:', predictions[i])\n",
    "print('True class: ' , y_test[i])\n",
    "print(\"********************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier got this example right (it predicted income $<=\\$50$K). Let's have a look at the explanation provided by LIME:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_explanation(exp1, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Task 4**: Please provide comments on the above explanation provided by LIME.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the age, hours per week, sex, occupation, workclass and race, LIME uses these features to explain why the prediction of the instance is in class label 0, which is <= $50K. Based on these features, it then gives a probability of the prediction of class, which is about 99% in this case. The features are categorised in descending order where the first feature contributes the most to the prediction. LIME then shows that these features plays an important role in placing the instance in the predicted class label 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Task 5**: Please change the value of one or two features the change the prediction of the classifier:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceModified1 = X_test.iloc[2]\n",
    "instanceModified1['Age'] = 70\n",
    "instanceModified1['Hours per week'] = 50\n",
    "print(instanceModified1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expM1 = explainer.explain_instance(instanceModified1.values, xgc_np.predict_proba, \n",
    "                                   distance_metric='euclidean', \n",
    "                                  num_features=len(instanceModified1.values))\n",
    "plot_explanation(expM1, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Task 6**:  How did you choose these features for which you have changed the value? How did you chose these values?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the prediction probability that the classifier predicted the instance to be <=$50K,  The \"age\" and the \"Hours per week\" are the top 2 features with the highest weightage that contributed to the output of the classifier. Therefore changing these two features will change the prediction of the classifier, classifying the instance in class label 1 instead of class label 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When a person's income > $50K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lime shows which features were the most influential in the model taking the correct decision of predicting the person's income as higher $\\$50$K. The below explanation shows features each contributing to push the model output from the base value (the average model output over the training dataset we passed) to the actual model output. Features pushing the prediction higher are shown in red, those pushing the prediction lower are in green."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Task 7**: Please find a person for which the income is > $\\$50$K and the prediction is correct.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change only the value of to select that person:\n",
    "j = 60\n",
    "###########\n",
    "\n",
    "exp2 = explainer.explain_instance(X_test.iloc[j].values, xgc_np.predict_proba, \n",
    "                                  distance_metric='euclidean', \n",
    "                                  num_features=len(X_test.iloc[j].values))\n",
    "proba2 = xgc_np.predict_proba(X_test.values)[j]\n",
    "\n",
    "print(\"********************\")\n",
    "print('Test id: ' , j)\n",
    "print('Probability(',exp2.class_names[0],\") =\", exp2.predict_proba[0])\n",
    "print('Probability(',exp2.class_names[1],\") =\", exp2.predict_proba[1])\n",
    "print('Predicted Label:', predictions[j])\n",
    "print('True class: ' , y_test[j])\n",
    "print(\"********************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier got this example right (it predicted income $>\\$50$K). Let's have a look at the explanation provided by LIME:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_explanation(exp2, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Task 8**: Please provide comments on the above explanation provided by LIME.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Education-Num, hours per week, marital status, occupation, relationship, sex, country and race, LIME uses these features to explain why the prediction of the instance is in class label 1, which is > $50K. Based on these features, it then gives a probability of the prediction of class, which is about 78.1% in this case. The features are categorised in descending order where the first feature contributes the most to the prediction. LIME then shows that these features plays an important role in placing the instance in the predicted class label 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Task 9**: Please change the value of one or two features the change the prediction of the classifier:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceModified2 = X_test.iloc[j]\n",
    "instanceModified2['Education-Num'] = 5\n",
    "instanceModified2['Hours per week'] = 30\n",
    "print(instanceModified2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expM2 = explainer.explain_instance(instanceModified2.values, xgc_np.predict_proba,\n",
    "                                   distance_metric='euclidean', \n",
    "                                  num_features=len(instanceModified2.values))\n",
    "plot_explanation(expM2, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Task 10**:  How did you choose these features for which you have changed the value? How did you chose these values?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the prediction probability that the classifier predicted the instance to be > $50K,  The \"Education-Num\" and the \"Hours per week\" are the top 2 features with the highest weightage that contributed to the output of the classifier. Therefore changing these two features will change the prediction of the classifier, classifying the instance in class label 0 instead of class label 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When a person's income actual is different than predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lime shows which features were the most influential in the model taking the incorrect decision of predicting the person's income. The below explanation shows features each contributing to push the model output from the base value (the average model output over the training dataset we passed) to the actual model output. Features pushing the prediction higher are shown in red, those pushing the prediction lower are in green."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Task 11**: Please find a person for which the the prediction is **incorrect**.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change only the value of to select that person:\n",
    "k = 4\n",
    "###########\n",
    "\n",
    "exp3 = explainer.explain_instance(X_test.iloc[k].values, xgc_np.predict_proba, \n",
    "                                  distance_metric='euclidean', \n",
    "                                  num_features=len(X_test.iloc[k].values))\n",
    "proba3 = xgc_np.predict_proba(X_test.values)[k]\n",
    "\n",
    "print(\"********************\")\n",
    "print('Test id: ' , k)\n",
    "print('Probability(',exp3.class_names[0],\") =\", exp3.predict_proba[0])\n",
    "print('Probability(',exp3.class_names[1],\") =\", exp3.predict_proba[1])\n",
    "print('Predicted Label:', predictions[k])\n",
    "print('True class: ' , y_test[k])\n",
    "print(\"********************\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier got this example classified incorrectly. Let's have a look at the explanation provided by LIME:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_explanation(exp3, mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Task 12**: Please provide comments on the above explanation provided by LIME.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Education-Num, hours per week, marital status, age, relationship, sex, occupation and country, LIME uses these features to explain why the prediction of the instance is in class label 1, which is > $50K although the actual class label is 0. Based on these features, it then gives a probability of the prediction of class, which is about 72.18% in this case. The features are categorised in descending order where the first feature contributes the most to the prediction. LIME then shows that these features plays an important role in placing the instance in the predicted class label 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Task 13**: Please change the value of one or two features the change the prediction of the classifier (to get a correct prediction):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceModified3 = X_test.iloc[4]\n",
    "instanceModified3['Education-Num'] = 5\n",
    "instanceModified3['Hours per week'] = 30\n",
    "print(instanceModified3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expM3 = explainer.explain_instance(instanceModified3.values, xgc_np.predict_proba, \n",
    "                                   distance_metric='euclidean', \n",
    "                                  num_features=len(instanceModified3.values))\n",
    "plot_explanation(expM3, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Task 14**:  How did you choose these features for which you have changed the value? How did you chose these values?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the prediction probability that the classifier predicted the instance to be > $50K,  The \"Education-Num\" and the \"Hours per week\" are the top 2 features with the highest weightage that contributed to the output of the classifier. Therefore changing these two features will change the prediction of the classifier, classifying the instance in class label 0 instead of class label 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "A decision tree is a decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.\n",
    "\n",
    "Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal, but are also a popular tool in machine learning.\n",
    "\n",
    "Let's use the DecisionTreeClassifier provided by sklearn on our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=0, max_depth=4).fit(X_train.values, y_train)\n",
    "tree.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tree.predict(X_test)\n",
    "print(\"The values predicted for the first 20 test examples are:\")\n",
    "print(predictions[:20])\n",
    "\n",
    "print(\"The true values are:\")\n",
    "print(y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = list(set(labels))\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_labels,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Task 15**:  Please provide comments on the performance of the decision Tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier has a relatively high accuracy, precision and recall score for label 0 but a relatively low accuracy, precision and recall score for label 1. The classifer is able to perform well to classify label 0 but perform poorly when classifying label 1. There is a higher number wrongly classified instances as compared to the correctly classified instance for class label 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualzing the Tree\n",
    "\n",
    "Let's generate a GraphViz representation of the decision tree:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(tree, out_file=dot_data, feature_names=headers, \n",
    "                filled=True, rounded=True, impurity= False, class_names=['<=$50K','>$50K'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph=pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Task 16**:  Explain the tree structure (including the meaning of the colors). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "At the first layer, which is the root node, the decision tree will predict the number of samples that \n",
    "belong to either class <=$50k or class >$50k based on the \"Relationship\" feature where the encoded label is <= 0.5. \n",
    "Since the most of the samples lie in class <=$50k at 17303 samples at the root node, it shows that the \n",
    "prediction the root node will make is class <=$50k. If the decision were to end at the root node, it would \n",
    "predict that all samples belonged to the class <=$50k.\n",
    "\n",
    "Based on a given feature of a sample, if it is true for Relationship <=0.5, the decision will move to the left \n",
    "but if it is false for Relationship <=0.5, the decision will move to the right.\n",
    "\n",
    "On the left cluster, if Relationship <=0.5 is true, the decision tree will make the next decision based on the \n",
    "Education-Num feature. If the encoded label for Education-Num is of value <= 12.5 is true, the decision will \n",
    "shift to the left, else, the decision will shift to the right.\n",
    "\n",
    "On the right cluster, if Relationship <=0.5 is false, the tree will make a decision if the encoded label of the \n",
    "sample with regards to the Relationship feature is of value <=4.5. If this is true, the decision will shift to \n",
    "the left. If this is false, the decision will shift to the right. \n",
    "\n",
    "This process goes on as the tree goes deeper until the nodes are homogeneous and each node will predict the \n",
    "specific class label if all the samples are predicted to be in that class.\n",
    "\n",
    "The shade of the nodes represent the predicted target values. \n",
    "\n",
    "The orange colour represents nodes that have more samples predicted to be class label 0, which is class <= $50k \n",
    "while the blue colour represents nodes that have more samples predicted to be class label 0, which is class > $50k.\n",
    "\n",
    "The white colour represents nodes that have almost equal number of samples in each class label. \n",
    "\n",
    "The lighter the colour, the lower the difference in samples between each class, thus a lower predicted value for \n",
    "the predicted class. The darker nodes indicate higher predicted values for the predicted class. \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation using LIME\n",
    "\n",
    "Select any person from the dataset and get the LIME explanation for its classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change only the value of to select that person:\n",
    "h = 5\n",
    "###########\n",
    "\n",
    "print(X_test.iloc[h].values.shape)\n",
    "\n",
    "exp4 = explainer.explain_instance(X_test.iloc[h].values, tree.predict_proba, \n",
    "                                  distance_metric='euclidean', \n",
    "                                  num_features=len(X_test.iloc[h].values))\n",
    "proba1 = tree.predict_proba(X_test.values)[h]\n",
    "\n",
    "print(\"********************\")\n",
    "print('Test id: ' , h)\n",
    "print('Probability(',exp4.class_names[0],\") =\", exp4.predict_proba[0])\n",
    "print('Probability(',exp4.class_names[1],\") =\", exp4.predict_proba[1])\n",
    "print('Predicted Label:', predictions[h])\n",
    "print('True class: ' , y_test[h])\n",
    "print(\"********************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_explanation(exp4, mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Task 17**:  Please provide comments on the above explanation provided by LIME using on the Tree structure above as a context to your explanation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Education-Num, relationship, age, hour per week, country, race and sex, LIME uses these features to explain why the prediction of the instance is in class label 0, which is <= $50K. Based on these features, it then gives a probability of the prediction of class, which is about 97.9% in this case. The features are categorised in descending order where the first feature contributes the most to the prediction. LIME then shows that these features plays an important role in placing the instance in the predicted class label 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your own test example\n",
    "\n",
    "**Task 18**: Following the tree above, create your own test example that will be classified as income > $\\$50$K by the decision tree. Explain how you select the values for the features. Use LIME to provide explanation to that test example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_instance = np.array([29, 4, 12, 2, 10, 5, 0, 1, 46, 39])\n",
    "\n",
    "exp4 = explainer.explain_instance(sample_instance, tree.predict_proba, \n",
    "                                  distance_metric='euclidean', \n",
    "                                  num_features=len(sample_instance))\n",
    "proba1 = tree.predict_proba([sample_instance])\n",
    "print(proba1)\n",
    "\n",
    "print(\"********************\")\n",
    "print('Test id: ' , 'sample_instance')\n",
    "print('Probability(',exp4.class_names[0],\") =\", exp4.predict_proba[0])\n",
    "print('Probability(',exp4.class_names[1],\") =\", exp4.predict_proba[1])\n",
    "print(\"********************\\n\\n\")\n",
    "\n",
    "plot_explanation(exp4, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the decision tree diagram, if Relationship <= 0.5 is false and Relationship <= 4.5 is false, it means \n",
    "that Relationship encoded label can only be 5, Education-Num <= 10.5 is false, so the encoded label 12 was \n",
    "selected, age<=25.5 is false, so the value selected is 29. The decision tree output at the node is predicted to\n",
    "be class label > $50k. For the rest of the features, it was an estimation using the XGBoost values where it \n",
    "predicted provided sample instance as class > $50k as XGBoost is an ensemble model that uses decision trees. \n",
    "Therefore, the sameple_instance can be predicted to be class > $50k.\n",
    "\n",
    "As the decision tree makes the first decision based on the Relationship feature, this means that the relationship\n",
    "contributes to the most in making the prediction. Therefore, as seen in the LIME description, the relationship has\n",
    "the highest weightage as compared to other features when the classifer decides to classify the sample_instance \n",
    "in class label > $50k.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You've come to the end of this assignment, and have seen a lot of the ways to explain the predictions given by a classifier.\n",
    "\n",
    "Congratulations on finishing this notebook! \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
