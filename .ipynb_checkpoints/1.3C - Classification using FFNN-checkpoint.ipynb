{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub [https://github.com/applecrumble123/SIT799---Human-Aligned-Artificial-Intelligence](https://github.com/applecrumble123/SIT799---Human-Aligned-Artificial-Intelligence.git)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your assignment this week! \n",
    "\n",
    "\n",
    "# Classification task\n",
    "\n",
    "In this task you are asked to build a simple Feed Forward Neural Network, train it and test it!\n",
    "\n",
    "\n",
    "**After this assignment you will be able to:**\n",
    "\n",
    "- Load a dataset.\n",
    "- Train a Feed Forward Neural Network.\n",
    "- Test a Feed Forward Neural Network.\n",
    "\n",
    "Let's get started! Run the following cell to install all the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (1.18.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: keras==2.2.4 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: h5py in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (5.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.18.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.4.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (2.3.0rc2)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.28.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0rc0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.3.0rc0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.14.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.0.0.post20200309)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (3.2.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: six in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /Users/johnathontoh/opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (46.0.0.post20200309)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install keras==2.2.4\n",
    "!pip install tensorflow\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to load the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will use consists of 4500 examples with 512 features. A label is given for each example to indicate positive and negative instances.\n",
    "\n",
    "Let's read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.index.values,\n",
    "    df.label.values,\n",
    "    test_size=0.15,\n",
    "    random_state=17,\n",
    "    stratify=df.label.values\n",
    ")\n",
    "df['data_type'] = ['note_set']*df.shape[0]\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_test, 'data_type'] = 'test'\n",
    "\n",
    "## The data to use:\n",
    "\n",
    "X_train = df[df['data_type']=='train'].iloc[:,:512].values\n",
    "X_test = df[df['data_type']=='test'].iloc[:,:512].values\n",
    "y_train = df[df['data_type']=='train'].iloc[:,512:513].values\n",
    "y_test = df[df['data_type']=='test'].iloc[:,512:513].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Build a Feed Forward Neural Network to address this classification task using the Keras framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START YOUR CODE HERE\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "FFNN = Sequential()\n",
    "FFNN.add(layers.Dense(units=10, name='fc1'))\n",
    "FFNN.add(layers.Dense(units=15, name='fc2'))\n",
    "FFNN.add(layers.Dense(units=20, name='fc3'))\n",
    "FFNN.add(layers.Dense(units=10, name='fc4'))\n",
    "FFNN.add(layers.Dense(units=1, name='output'))\n",
    "\n",
    "adamopt_FNN = Adam(lr=0.0001)\n",
    "FFNN.compile(optimizer= adamopt_FNN, loss = 'binary_crossentropy', metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Now, let's start our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "60/60 [==============================] - 0s 789us/step - loss: 5.8875 - accuracy: 0.4711\n",
      "Epoch 2/200\n",
      "60/60 [==============================] - 0s 704us/step - loss: 5.5690 - accuracy: 0.4868\n",
      "Epoch 3/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 5.3694 - accuracy: 0.4978\n",
      "Epoch 4/200\n",
      "60/60 [==============================] - 0s 677us/step - loss: 5.1775 - accuracy: 0.5145\n",
      "Epoch 5/200\n",
      "60/60 [==============================] - 0s 679us/step - loss: 4.8832 - accuracy: 0.5318\n",
      "Epoch 6/200\n",
      "60/60 [==============================] - 0s 706us/step - loss: 4.6614 - accuracy: 0.5422\n",
      "Epoch 7/200\n",
      "60/60 [==============================] - 0s 691us/step - loss: 4.5989 - accuracy: 0.5472\n",
      "Epoch 8/200\n",
      "60/60 [==============================] - 0s 686us/step - loss: 4.5395 - accuracy: 0.5498\n",
      "Epoch 9/200\n",
      "60/60 [==============================] - 0s 688us/step - loss: 4.5035 - accuracy: 0.5529\n",
      "Epoch 10/200\n",
      "60/60 [==============================] - 0s 672us/step - loss: 4.4775 - accuracy: 0.5553\n",
      "Epoch 11/200\n",
      "60/60 [==============================] - 0s 707us/step - loss: 4.4433 - accuracy: 0.5584\n",
      "Epoch 12/200\n",
      "60/60 [==============================] - 0s 688us/step - loss: 4.3795 - accuracy: 0.5608\n",
      "Epoch 13/200\n",
      "60/60 [==============================] - 0s 675us/step - loss: 4.3260 - accuracy: 0.5673\n",
      "Epoch 14/200\n",
      "60/60 [==============================] - 0s 720us/step - loss: 4.2068 - accuracy: 0.5791\n",
      "Epoch 15/200\n",
      "60/60 [==============================] - 0s 673us/step - loss: 4.1093 - accuracy: 0.5869\n",
      "Epoch 16/200\n",
      "60/60 [==============================] - 0s 693us/step - loss: 4.0551 - accuracy: 0.5898\n",
      "Epoch 17/200\n",
      "60/60 [==============================] - 0s 704us/step - loss: 3.9634 - accuracy: 0.5971\n",
      "Epoch 18/200\n",
      "60/60 [==============================] - 0s 702us/step - loss: 3.9021 - accuracy: 0.6024\n",
      "Epoch 19/200\n",
      "60/60 [==============================] - 0s 745us/step - loss: 3.8598 - accuracy: 0.6047\n",
      "Epoch 20/200\n",
      "60/60 [==============================] - 0s 693us/step - loss: 3.7175 - accuracy: 0.6146\n",
      "Epoch 21/200\n",
      "60/60 [==============================] - 0s 696us/step - loss: 3.5984 - accuracy: 0.6220\n",
      "Epoch 22/200\n",
      "60/60 [==============================] - 0s 689us/step - loss: 3.5265 - accuracy: 0.6259\n",
      "Epoch 23/200\n",
      "60/60 [==============================] - 0s 687us/step - loss: 3.3981 - accuracy: 0.6324\n",
      "Epoch 24/200\n",
      "60/60 [==============================] - 0s 693us/step - loss: 3.4062 - accuracy: 0.6275\n",
      "Epoch 25/200\n",
      "60/60 [==============================] - 0s 689us/step - loss: 3.3746 - accuracy: 0.6295\n",
      "Epoch 26/200\n",
      "60/60 [==============================] - 0s 693us/step - loss: 3.3128 - accuracy: 0.6356\n",
      "Epoch 27/200\n",
      "60/60 [==============================] - 0s 703us/step - loss: 3.3037 - accuracy: 0.6369\n",
      "Epoch 28/200\n",
      "60/60 [==============================] - 0s 736us/step - loss: 3.2909 - accuracy: 0.6374\n",
      "Epoch 29/200\n",
      "60/60 [==============================] - 0s 703us/step - loss: 3.2648 - accuracy: 0.6369\n",
      "Epoch 30/200\n",
      "60/60 [==============================] - 0s 741us/step - loss: 3.2433 - accuracy: 0.6374\n",
      "Epoch 31/200\n",
      "60/60 [==============================] - 0s 763us/step - loss: 3.2079 - accuracy: 0.6397\n",
      "Epoch 32/200\n",
      "60/60 [==============================] - 0s 710us/step - loss: 3.1839 - accuracy: 0.6413\n",
      "Epoch 33/200\n",
      "60/60 [==============================] - 0s 710us/step - loss: 3.1673 - accuracy: 0.6431\n",
      "Epoch 34/200\n",
      "60/60 [==============================] - 0s 716us/step - loss: 3.1542 - accuracy: 0.6444\n",
      "Epoch 35/200\n",
      "60/60 [==============================] - 0s 743us/step - loss: 3.1393 - accuracy: 0.6455\n",
      "Epoch 36/200\n",
      "60/60 [==============================] - 0s 669us/step - loss: 3.1290 - accuracy: 0.6484\n",
      "Epoch 37/200\n",
      "60/60 [==============================] - 0s 710us/step - loss: 3.1161 - accuracy: 0.6497\n",
      "Epoch 38/200\n",
      "60/60 [==============================] - 0s 701us/step - loss: 3.0830 - accuracy: 0.6505\n",
      "Epoch 39/200\n",
      "60/60 [==============================] - 0s 701us/step - loss: 3.0276 - accuracy: 0.6549\n",
      "Epoch 40/200\n",
      "60/60 [==============================] - 0s 693us/step - loss: 2.9896 - accuracy: 0.6559\n",
      "Epoch 41/200\n",
      "60/60 [==============================] - 0s 735us/step - loss: 2.9403 - accuracy: 0.6573\n",
      "Epoch 42/200\n",
      "60/60 [==============================] - 0s 705us/step - loss: 2.8861 - accuracy: 0.6588\n",
      "Epoch 43/200\n",
      "60/60 [==============================] - 0s 685us/step - loss: 2.8596 - accuracy: 0.6614\n",
      "Epoch 44/200\n",
      "60/60 [==============================] - 0s 725us/step - loss: 2.8473 - accuracy: 0.6625\n",
      "Epoch 45/200\n",
      "60/60 [==============================] - 0s 687us/step - loss: 2.8364 - accuracy: 0.6641\n",
      "Epoch 46/200\n",
      "60/60 [==============================] - 0s 772us/step - loss: 2.7985 - accuracy: 0.6667\n",
      "Epoch 47/200\n",
      "60/60 [==============================] - 0s 739us/step - loss: 2.7760 - accuracy: 0.6688\n",
      "Epoch 48/200\n",
      "60/60 [==============================] - 0s 698us/step - loss: 2.7595 - accuracy: 0.6722\n",
      "Epoch 49/200\n",
      "60/60 [==============================] - 0s 699us/step - loss: 2.7493 - accuracy: 0.6737\n",
      "Epoch 50/200\n",
      "60/60 [==============================] - 0s 711us/step - loss: 2.7150 - accuracy: 0.6769\n",
      "Epoch 51/200\n",
      "60/60 [==============================] - 0s 690us/step - loss: 2.6653 - accuracy: 0.6831\n",
      "Epoch 52/200\n",
      "60/60 [==============================] - 0s 704us/step - loss: 2.6425 - accuracy: 0.6860\n",
      "Epoch 53/200\n",
      "60/60 [==============================] - 0s 732us/step - loss: 2.5754 - accuracy: 0.6897\n",
      "Epoch 54/200\n",
      "60/60 [==============================] - 0s 711us/step - loss: 2.4683 - accuracy: 0.6967\n",
      "Epoch 55/200\n",
      "60/60 [==============================] - 0s 705us/step - loss: 2.4408 - accuracy: 0.6983\n",
      "Epoch 56/200\n",
      "60/60 [==============================] - 0s 666us/step - loss: 2.4106 - accuracy: 0.6991\n",
      "Epoch 57/200\n",
      "60/60 [==============================] - 0s 672us/step - loss: 2.3990 - accuracy: 0.7001\n",
      "Epoch 58/200\n",
      "60/60 [==============================] - 0s 683us/step - loss: 2.3885 - accuracy: 0.7014\n",
      "Epoch 59/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 2.3820 - accuracy: 0.7025\n",
      "Epoch 60/200\n",
      "60/60 [==============================] - 0s 655us/step - loss: 2.3777 - accuracy: 0.7038\n",
      "Epoch 61/200\n",
      "60/60 [==============================] - 0s 672us/step - loss: 2.3671 - accuracy: 0.7041\n",
      "Epoch 62/200\n",
      "60/60 [==============================] - 0s 673us/step - loss: 2.3522 - accuracy: 0.7046\n",
      "Epoch 63/200\n",
      "60/60 [==============================] - 0s 663us/step - loss: 2.3341 - accuracy: 0.7064\n",
      "Epoch 64/200\n",
      "60/60 [==============================] - 0s 674us/step - loss: 2.2962 - accuracy: 0.7075\n",
      "Epoch 65/200\n",
      "60/60 [==============================] - 0s 677us/step - loss: 2.2609 - accuracy: 0.7122\n",
      "Epoch 66/200\n",
      "60/60 [==============================] - 0s 671us/step - loss: 2.2159 - accuracy: 0.7161\n",
      "Epoch 67/200\n",
      "60/60 [==============================] - 0s 664us/step - loss: 2.1865 - accuracy: 0.7171\n",
      "Epoch 68/200\n",
      "60/60 [==============================] - 0s 672us/step - loss: 2.1328 - accuracy: 0.7218\n",
      "Epoch 69/200\n",
      "60/60 [==============================] - 0s 677us/step - loss: 2.1222 - accuracy: 0.7234\n",
      "Epoch 70/200\n",
      "60/60 [==============================] - 0s 673us/step - loss: 2.1108 - accuracy: 0.7244\n",
      "Epoch 71/200\n",
      "60/60 [==============================] - 0s 670us/step - loss: 2.0960 - accuracy: 0.7252\n",
      "Epoch 72/200\n",
      "60/60 [==============================] - 0s 670us/step - loss: 2.0806 - accuracy: 0.7258\n",
      "Epoch 73/200\n",
      "60/60 [==============================] - 0s 670us/step - loss: 2.0528 - accuracy: 0.7273\n",
      "Epoch 74/200\n",
      "60/60 [==============================] - 0s 665us/step - loss: 2.0296 - accuracy: 0.7292\n",
      "Epoch 75/200\n",
      "60/60 [==============================] - 0s 671us/step - loss: 2.0083 - accuracy: 0.7312\n",
      "Epoch 76/200\n",
      "60/60 [==============================] - 0s 662us/step - loss: 1.9802 - accuracy: 0.7333\n",
      "Epoch 77/200\n",
      "60/60 [==============================] - 0s 669us/step - loss: 1.9521 - accuracy: 0.7354\n",
      "Epoch 78/200\n",
      "60/60 [==============================] - 0s 667us/step - loss: 1.9271 - accuracy: 0.7380\n",
      "Epoch 79/200\n",
      "60/60 [==============================] - 0s 670us/step - loss: 1.9074 - accuracy: 0.7393\n",
      "Epoch 80/200\n",
      "60/60 [==============================] - 0s 679us/step - loss: 1.8694 - accuracy: 0.7412\n",
      "Epoch 81/200\n",
      "60/60 [==============================] - 0s 664us/step - loss: 1.8434 - accuracy: 0.7461\n",
      "Epoch 82/200\n",
      "60/60 [==============================] - 0s 667us/step - loss: 1.8197 - accuracy: 0.7482\n",
      "Epoch 83/200\n",
      "60/60 [==============================] - 0s 677us/step - loss: 1.7705 - accuracy: 0.7511\n",
      "Epoch 84/200\n",
      "60/60 [==============================] - 0s 660us/step - loss: 1.7462 - accuracy: 0.7535\n",
      "Epoch 85/200\n",
      "60/60 [==============================] - 0s 661us/step - loss: 1.7182 - accuracy: 0.7548\n",
      "Epoch 86/200\n",
      "60/60 [==============================] - 0s 662us/step - loss: 1.6976 - accuracy: 0.7574\n",
      "Epoch 87/200\n",
      "60/60 [==============================] - 0s 666us/step - loss: 1.6738 - accuracy: 0.7613\n",
      "Epoch 88/200\n",
      "60/60 [==============================] - 0s 671us/step - loss: 1.6555 - accuracy: 0.7631\n",
      "Epoch 89/200\n",
      "60/60 [==============================] - 0s 668us/step - loss: 1.6391 - accuracy: 0.7639\n",
      "Epoch 90/200\n",
      "60/60 [==============================] - 0s 669us/step - loss: 1.5952 - accuracy: 0.7668\n",
      "Epoch 91/200\n",
      "60/60 [==============================] - 0s 661us/step - loss: 1.5695 - accuracy: 0.7684\n",
      "Epoch 92/200\n",
      "60/60 [==============================] - 0s 666us/step - loss: 1.5526 - accuracy: 0.7731\n",
      "Epoch 93/200\n",
      "60/60 [==============================] - 0s 658us/step - loss: 1.5262 - accuracy: 0.7767\n",
      "Epoch 94/200\n",
      "60/60 [==============================] - 0s 671us/step - loss: 1.5163 - accuracy: 0.7786\n",
      "Epoch 95/200\n",
      "60/60 [==============================] - 0s 670us/step - loss: 1.5060 - accuracy: 0.7812\n",
      "Epoch 96/200\n",
      "60/60 [==============================] - 0s 667us/step - loss: 1.4649 - accuracy: 0.7833\n",
      "Epoch 97/200\n",
      "60/60 [==============================] - 0s 666us/step - loss: 1.4452 - accuracy: 0.7843\n",
      "Epoch 98/200\n",
      "60/60 [==============================] - 0s 666us/step - loss: 1.4329 - accuracy: 0.7864\n",
      "Epoch 99/200\n",
      "60/60 [==============================] - 0s 654us/step - loss: 1.4273 - accuracy: 0.7877\n",
      "Epoch 100/200\n",
      "60/60 [==============================] - 0s 666us/step - loss: 1.3968 - accuracy: 0.7901\n",
      "Epoch 101/200\n",
      "60/60 [==============================] - 0s 669us/step - loss: 1.3554 - accuracy: 0.7950\n",
      "Epoch 102/200\n",
      "60/60 [==============================] - 0s 664us/step - loss: 1.3381 - accuracy: 0.7982\n",
      "Epoch 103/200\n",
      "60/60 [==============================] - 0s 668us/step - loss: 1.3131 - accuracy: 0.8013\n",
      "Epoch 104/200\n",
      "60/60 [==============================] - 0s 667us/step - loss: 1.2933 - accuracy: 0.8047\n",
      "Epoch 105/200\n",
      "60/60 [==============================] - 0s 664us/step - loss: 1.2609 - accuracy: 0.8071\n",
      "Epoch 106/200\n",
      "60/60 [==============================] - 0s 681us/step - loss: 1.2457 - accuracy: 0.8105\n",
      "Epoch 107/200\n",
      "60/60 [==============================] - 0s 676us/step - loss: 1.2385 - accuracy: 0.8118\n",
      "Epoch 108/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 1.2071 - accuracy: 0.8131\n",
      "Epoch 109/200\n",
      "60/60 [==============================] - 0s 673us/step - loss: 1.1548 - accuracy: 0.8170\n",
      "Epoch 110/200\n",
      "60/60 [==============================] - 0s 670us/step - loss: 1.1375 - accuracy: 0.8220\n",
      "Epoch 111/200\n",
      "60/60 [==============================] - 0s 663us/step - loss: 1.1242 - accuracy: 0.8225\n",
      "Epoch 112/200\n",
      "60/60 [==============================] - 0s 657us/step - loss: 1.1095 - accuracy: 0.8238\n",
      "Epoch 113/200\n",
      "60/60 [==============================] - 0s 669us/step - loss: 1.1000 - accuracy: 0.8272\n",
      "Epoch 114/200\n",
      "60/60 [==============================] - 0s 666us/step - loss: 1.0803 - accuracy: 0.8306\n",
      "Epoch 115/200\n",
      "60/60 [==============================] - 0s 673us/step - loss: 1.0583 - accuracy: 0.8335\n",
      "Epoch 116/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 1.0424 - accuracy: 0.8353\n",
      "Epoch 117/200\n",
      "60/60 [==============================] - 0s 671us/step - loss: 1.0165 - accuracy: 0.8363\n",
      "Epoch 118/200\n",
      "60/60 [==============================] - 0s 675us/step - loss: 0.9989 - accuracy: 0.8376\n",
      "Epoch 119/200\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.9871 - accuracy: 0.8395\n",
      "Epoch 120/200\n",
      "60/60 [==============================] - 0s 670us/step - loss: 0.9795 - accuracy: 0.8408\n",
      "Epoch 121/200\n",
      "60/60 [==============================] - 0s 671us/step - loss: 0.9401 - accuracy: 0.8463\n",
      "Epoch 122/200\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.8990 - accuracy: 0.8478\n",
      "Epoch 123/200\n",
      "60/60 [==============================] - 0s 669us/step - loss: 0.8539 - accuracy: 0.8520\n",
      "Epoch 124/200\n",
      "60/60 [==============================] - 0s 670us/step - loss: 0.8278 - accuracy: 0.8559\n",
      "Epoch 125/200\n",
      "60/60 [==============================] - 0s 684us/step - loss: 0.8137 - accuracy: 0.8565\n",
      "Epoch 126/200\n",
      "60/60 [==============================] - 0s 671us/step - loss: 0.7948 - accuracy: 0.8567\n",
      "Epoch 127/200\n",
      "60/60 [==============================] - 0s 672us/step - loss: 0.7874 - accuracy: 0.8588\n",
      "Epoch 128/200\n",
      "60/60 [==============================] - 0s 671us/step - loss: 0.7701 - accuracy: 0.8620\n",
      "Epoch 129/200\n",
      "60/60 [==============================] - 0s 669us/step - loss: 0.7527 - accuracy: 0.8641\n",
      "Epoch 130/200\n",
      "60/60 [==============================] - 0s 672us/step - loss: 0.7376 - accuracy: 0.8667\n",
      "Epoch 131/200\n",
      "60/60 [==============================] - 0s 678us/step - loss: 0.7205 - accuracy: 0.8688\n",
      "Epoch 132/200\n",
      "60/60 [==============================] - 0s 670us/step - loss: 0.7025 - accuracy: 0.8716\n",
      "Epoch 133/200\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.6512 - accuracy: 0.8748\n",
      "Epoch 134/200\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.6229 - accuracy: 0.8782\n",
      "Epoch 135/200\n",
      "60/60 [==============================] - 0s 678us/step - loss: 0.6162 - accuracy: 0.8816\n",
      "Epoch 136/200\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.6095 - accuracy: 0.8831\n",
      "Epoch 137/200\n",
      "60/60 [==============================] - 0s 673us/step - loss: 0.5993 - accuracy: 0.8842\n",
      "Epoch 138/200\n",
      "60/60 [==============================] - 0s 672us/step - loss: 0.5899 - accuracy: 0.8860\n",
      "Epoch 139/200\n",
      "60/60 [==============================] - 0s 675us/step - loss: 0.5779 - accuracy: 0.8873\n",
      "Epoch 140/200\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.5737 - accuracy: 0.8894\n",
      "Epoch 141/200\n",
      "60/60 [==============================] - 0s 674us/step - loss: 0.5676 - accuracy: 0.8912\n",
      "Epoch 142/200\n",
      "60/60 [==============================] - 0s 685us/step - loss: 0.5632 - accuracy: 0.8925\n",
      "Epoch 143/200\n",
      "60/60 [==============================] - 0s 678us/step - loss: 0.5429 - accuracy: 0.8936\n",
      "Epoch 144/200\n",
      "60/60 [==============================] - 0s 682us/step - loss: 0.5222 - accuracy: 0.8949\n",
      "Epoch 145/200\n",
      "60/60 [==============================] - 0s 673us/step - loss: 0.5090 - accuracy: 0.8965\n",
      "Epoch 146/200\n",
      "60/60 [==============================] - 0s 672us/step - loss: 0.5016 - accuracy: 0.8991\n",
      "Epoch 147/200\n",
      "60/60 [==============================] - 0s 675us/step - loss: 0.4941 - accuracy: 0.9001\n",
      "Epoch 148/200\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.4908 - accuracy: 0.9027\n",
      "Epoch 149/200\n",
      "60/60 [==============================] - 0s 683us/step - loss: 0.4826 - accuracy: 0.9043\n",
      "Epoch 150/200\n",
      "60/60 [==============================] - 0s 674us/step - loss: 0.4692 - accuracy: 0.9067\n",
      "Epoch 151/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 0.4632 - accuracy: 0.9088\n",
      "Epoch 152/200\n",
      "60/60 [==============================] - 0s 692us/step - loss: 0.4563 - accuracy: 0.9111\n",
      "Epoch 153/200\n",
      "60/60 [==============================] - 0s 668us/step - loss: 0.4528 - accuracy: 0.9124\n",
      "Epoch 154/200\n",
      "60/60 [==============================] - 0s 679us/step - loss: 0.4447 - accuracy: 0.9135\n",
      "Epoch 155/200\n",
      "60/60 [==============================] - 0s 671us/step - loss: 0.4261 - accuracy: 0.9153\n",
      "Epoch 156/200\n",
      "60/60 [==============================] - 0s 678us/step - loss: 0.4058 - accuracy: 0.9176\n",
      "Epoch 157/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 0.3911 - accuracy: 0.9197\n",
      "Epoch 158/200\n",
      "60/60 [==============================] - 0s 694us/step - loss: 0.3802 - accuracy: 0.9218\n",
      "Epoch 159/200\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.3765 - accuracy: 0.9221\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 698us/step - loss: 0.3708 - accuracy: 0.9242\n",
      "Epoch 161/200\n",
      "60/60 [==============================] - 0s 679us/step - loss: 0.3614 - accuracy: 0.9278\n",
      "Epoch 162/200\n",
      "60/60 [==============================] - 0s 679us/step - loss: 0.3573 - accuracy: 0.9299\n",
      "Epoch 163/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 0.3546 - accuracy: 0.9305\n",
      "Epoch 164/200\n",
      "60/60 [==============================] - 0s 686us/step - loss: 0.3475 - accuracy: 0.9312\n",
      "Epoch 165/200\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.3228 - accuracy: 0.9357\n",
      "Epoch 166/200\n",
      "60/60 [==============================] - 0s 689us/step - loss: 0.3124 - accuracy: 0.9378\n",
      "Epoch 167/200\n",
      "60/60 [==============================] - 0s 674us/step - loss: 0.3083 - accuracy: 0.9386\n",
      "Epoch 168/200\n",
      "60/60 [==============================] - 0s 762us/step - loss: 0.3053 - accuracy: 0.9407\n",
      "Epoch 169/200\n",
      "60/60 [==============================] - 0s 674us/step - loss: 0.2999 - accuracy: 0.9438\n",
      "Epoch 170/200\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.2960 - accuracy: 0.9451\n",
      "Epoch 171/200\n",
      "60/60 [==============================] - 0s 678us/step - loss: 0.2933 - accuracy: 0.9461\n",
      "Epoch 172/200\n",
      "60/60 [==============================] - 0s 688us/step - loss: 0.2824 - accuracy: 0.9464\n",
      "Epoch 173/200\n",
      "60/60 [==============================] - 0s 723us/step - loss: 0.2778 - accuracy: 0.9472\n",
      "Epoch 174/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 0.2725 - accuracy: 0.9475\n",
      "Epoch 175/200\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.2659 - accuracy: 0.9488\n",
      "Epoch 176/200\n",
      "60/60 [==============================] - 0s 673us/step - loss: 0.2634 - accuracy: 0.9490\n",
      "Epoch 177/200\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.2610 - accuracy: 0.9501\n",
      "Epoch 178/200\n",
      "60/60 [==============================] - 0s 684us/step - loss: 0.2587 - accuracy: 0.9514\n",
      "Epoch 179/200\n",
      "60/60 [==============================] - 0s 677us/step - loss: 0.2420 - accuracy: 0.9532\n",
      "Epoch 180/200\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.2373 - accuracy: 0.9545\n",
      "Epoch 181/200\n",
      "60/60 [==============================] - 0s 678us/step - loss: 0.2343 - accuracy: 0.9550\n",
      "Epoch 182/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 0.2287 - accuracy: 0.9563\n",
      "Epoch 183/200\n",
      "60/60 [==============================] - 0s 680us/step - loss: 0.2255 - accuracy: 0.9571\n",
      "Epoch 184/200\n",
      "60/60 [==============================] - 0s 679us/step - loss: 0.2231 - accuracy: 0.9592\n",
      "Epoch 185/200\n",
      "60/60 [==============================] - 0s 678us/step - loss: 0.2209 - accuracy: 0.9597\n",
      "Epoch 186/200\n",
      "60/60 [==============================] - 0s 666us/step - loss: 0.2109 - accuracy: 0.9605\n",
      "Epoch 187/200\n",
      "60/60 [==============================] - 0s 675us/step - loss: 0.2065 - accuracy: 0.9618\n",
      "Epoch 188/200\n",
      "60/60 [==============================] - 0s 674us/step - loss: 0.2044 - accuracy: 0.9621\n",
      "Epoch 189/200\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.2024 - accuracy: 0.9626\n",
      "Epoch 190/200\n",
      "60/60 [==============================] - 0s 690us/step - loss: 0.2005 - accuracy: 0.9629\n",
      "Epoch 191/200\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.1986 - accuracy: 0.9639\n",
      "Epoch 192/200\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.1969 - accuracy: 0.9644\n",
      "Epoch 193/200\n",
      "60/60 [==============================] - 0s 690us/step - loss: 0.1951 - accuracy: 0.9655\n",
      "Epoch 194/200\n",
      "60/60 [==============================] - 0s 683us/step - loss: 0.1934 - accuracy: 0.9671\n",
      "Epoch 195/200\n",
      "60/60 [==============================] - 0s 690us/step - loss: 0.1917 - accuracy: 0.9676\n",
      "Epoch 196/200\n",
      "60/60 [==============================] - 0s 675us/step - loss: 0.1901 - accuracy: 0.9689\n",
      "Epoch 197/200\n",
      "60/60 [==============================] - 0s 676us/step - loss: 0.1884 - accuracy: 0.9689\n",
      "Epoch 198/200\n",
      "60/60 [==============================] - 0s 673us/step - loss: 0.1868 - accuracy: 0.9692\n",
      "Epoch 199/200\n",
      "60/60 [==============================] - 0s 678us/step - loss: 0.1830 - accuracy: 0.9707\n",
      "Epoch 200/200\n",
      "60/60 [==============================] - 0s 688us/step - loss: 0.1804 - accuracy: 0.9710\n"
     ]
    }
   ],
   "source": [
    "history = FFNN.fit(X_train, y_train, epochs=200, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "Test the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 511us/step - loss: 0.2308 - accuracy: 0.9541\n"
     ]
    }
   ],
   "source": [
    "# START YOUR CODE HERE\n",
    "loss_and_metrics = FFNN.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You've come to the end of this assignment, and you have built your first neural network. \n",
    "\n",
    "Congratulations on finishing this notebook! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "8hb5s",
   "launcher_item_id": "5NrJ6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
